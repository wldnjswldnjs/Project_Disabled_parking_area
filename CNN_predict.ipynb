{"cells":[{"cell_type":"code","execution_count":null,"id":"86319ddf","metadata":{"id":"86319ddf","scrolled":true},"outputs":[],"source":["import os\n","import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","import torch\n","from glob import glob\n","\n","import efficientnet\n","import efficientnet.tfkeras as efn\n","\n","from tensorflow.keras.models import load_model\n","from keras.preprocessing import image\n","\n","from IPython.display import Image"]},{"cell_type":"code","execution_count":null,"id":"62ac4f1f","metadata":{"id":"62ac4f1f","scrolled":true},"outputs":[],"source":["new_model = load_model('./e_final_model_5.h5')"]},{"cell_type":"markdown","id":"58d6030f","metadata":{"id":"58d6030f"},"source":["### ÏòàÏ∏°Ìï† Ïù¥ÎØ∏ÏßÄ Î∂àÎü¨Ïò§Í∏∞"]},{"cell_type":"code","execution_count":null,"id":"5e153f8e","metadata":{"id":"5e153f8e","outputId":"0a96b9e6-91e9-4e19-aa2a-612a1bfb6dbd"},"outputs":[{"name":"stdout","output_type":"stream","text":["8\n"]}],"source":["img_list = glob('/home/lab30/jupyter_home/test/*.jpg')\n","\n","print(len(img_list)) # Î™®Îì† Ïù¥ÎØ∏ÏßÄÏùò Í∞úÏàò ÌôïÏù∏"]},{"cell_type":"code","execution_count":null,"id":"e12da153","metadata":{"id":"e12da153","outputId":"efb5f6b6-9259-4a9d-9ba1-f0b3476cf488"},"outputs":[{"name":"stdout","output_type":"stream","text":["/home/lab30/jupyter_home/yolov5\n"]}],"source":["cd /home/lab30/jupyter_home/yolov5"]},{"cell_type":"code","execution_count":null,"id":"fd3f7000","metadata":{"id":"fd3f7000","outputId":"b3a1d52e-88e3-4def-9ca8-84e6156abea1","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['./runs/train/best.pt'], source=/home/lab30/jupyter_home/test/es_img_1 (5).jpg, data=data/coco128.yaml, imgsz=[416, 416], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n","YOLOv5 üöÄ v6.1-246-g2dd3db0 Python-3.8.13 torch-1.11.0+cu102 CUDA:0 (Tesla T4, 15110MiB)\n","\n","Traceback (most recent call last):\n","  File \"detect.py\", line 252, in <module>\n","    main(opt)\n","  File \"detect.py\", line 247, in main\n","    run(**vars(opt))\n","  File \"/home/ubuntu/anaconda3/envs/project_cnn/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 27, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"detect.py\", line 92, in run\n","    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n","  File \"/home/lab30/jupyter_home/yolov5/models/common.py\", line 334, in __init__\n","    model = attempt_load(weights if isinstance(weights, list) else w, device=device)\n","  File \"/home/lab30/jupyter_home/yolov5/models/experimental.py\", line 81, in attempt_load\n","    ckpt = (ckpt.get('ema') or ckpt['model']).to(device).float()  # FP32 model\n","  File \"/home/ubuntu/anaconda3/envs/project_cnn/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 907, in to\n","    return self._apply(convert)\n","  File \"/home/lab30/jupyter_home/yolov5/models/yolo.py\", line 242, in _apply\n","    self = super()._apply(fn)\n","  File \"/home/ubuntu/anaconda3/envs/project_cnn/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 578, in _apply\n","    module._apply(fn)\n","  File \"/home/ubuntu/anaconda3/envs/project_cnn/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 578, in _apply\n","    module._apply(fn)\n","  File \"/home/ubuntu/anaconda3/envs/project_cnn/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 578, in _apply\n","    module._apply(fn)\n","  File \"/home/ubuntu/anaconda3/envs/project_cnn/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 601, in _apply\n","    param_applied = fn(param)\n","  File \"/home/ubuntu/anaconda3/envs/project_cnn/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 905, in convert\n","    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n","RuntimeError: CUDA error: out of memory\n","CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n","For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n"]}],"source":["os.environ['MKL_THREADING_LAYER'] = 'GNU'\n","\n","img_path = img_list[1]\n","\n","!python detect.py --weights ./runs/train/best.pt --img 416 --conf 0.5 --source \"{img_path}\" --save-crop"]},{"cell_type":"markdown","id":"85c5df5a","metadata":{"id":"85c5df5a"},"source":["###  cropÎêú Ïù¥ÎØ∏ÏßÄ Î∂àÎü¨Ïò§Í∏∞"]},{"cell_type":"code","execution_count":null,"id":"2993d4f5","metadata":{"id":"2993d4f5","outputId":"e30fedb5-995b-46c2-9e66-a6af4bd2af62"},"outputs":[{"name":"stdout","output_type":"stream","text":["disable1\n","/home/lab30/jupyter_home/yolov5/runs/detect/exp/crops/disable1/crop4.jpg\n"]}],"source":["# detect ÌïòÏúÑ dir Í≤ΩÎ°ú Î∞è Ìï¥Îãπ dir name (concat)\n","subfolders = pd.DataFrame([ f.path for f in os.scandir('/home/lab30/jupyter_home/yolov5/runs/detect/') if f.is_dir() ], columns = ['dir_path'])\n","subfolders_nm = pd.DataFrame([ f.name for f in os.scandir('/home/lab30/jupyter_home/yolov5/runs/detect/') if f.is_dir() ], columns = ['dir_name'])\n","subfolders_frm = pd.concat([subfolders, subfolders_nm], axis=1)\n","\n","# checkpoints dir Ï†úÍ±∞(ÏÇ¨Ïö©Ìï† ÏµúÏ¢Ö data) : sub_exp_frm\n","sub_exp_frm = subfolders_frm.loc[~subfolders_frm.dir_name.str.contains('check'),:]\n","\n","# exp Îí§Ïùò Ïà´ÏûêÍ∞Ä Í∞ÄÏû• ÌÅ∞ dir Ï∞æÍ∏∞ (Í∞ÄÏû• ÏµúÏã† detection) : new_dir\n","new_idx = sub_exp_frm.dir_name.str[3:].replace('',0).astype(int).argmax() # Ìï¥Îãπ dir ÏûàÎäî index number\n","new_dir = sub_exp_frm.iloc[new_idx, 0]\n","\n","if 'crops' in os.listdir(new_dir) :\n","    for (path, dir, files) in os.walk(new_dir + '/crops/') :\n","        for filename in files :\n","            ext = os.path.splitext(filename)[-1]\n","            if ext == '.JPG' or ext == '.jpg' :\n","                label_nm = path.split('/')[-1]\n","                crop_img_path = '%s/%s'% (path, filename)\n","                print(label_nm)\n","                print(crop_img_path)\n","else :\n","    print(\"No crop image\")"]},{"cell_type":"markdown","id":"ea219d79","metadata":{"id":"ea219d79"},"source":["### predict"]},{"cell_type":"code","execution_count":null,"id":"5765946f","metadata":{"id":"5765946f","outputId":"73458489-b284-4a75-ddf3-d0e66d3b7323"},"outputs":[{"data":{"text/plain":["0.9874752"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","from keras.preprocessing import image\n","    \n","\n","test_image = image.load_img(crop_img_path, target_size = (150, 150))\n","\n","test_image = image.img_to_array(test_image)\n","\n","test_image = np.expand_dims(test_image, axis = 0)\n","\n","result = new_model.predict(test_image)\n","\n","np.max(result)\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"CNN_predict.ipynb","provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"0199bbf5df4ad7c62233e7a6971770a9c8af15db9a7b63bc190fc9c0bfb8bc7b"}}},"nbformat":4,"nbformat_minor":5}
